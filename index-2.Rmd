---
title: "Homework 9 - Alligators"
author: "Ammar Plumber, Elaina Lin, Kim Nguyen, Meghan Aines, Ryan Karbowicz"
date: "4/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## I. Introduction

Social media has been evolved and affected our lives in many aspects. In this assignment, we aim to have a closer look at the two most popular social media platforms: Tiktok and Facebook. These platforms are in a similar industry but with very different target audiences, thus the two brands and their audiences could differ in their communication styles and language. Understanding the language used in these platforms may lead to their business implications and directions. 

Our research question focuses on whether there are differences in sentiments of tweet communications between Tiktok and Facebook account. 

## II. Methodology

Our method of sentiments analysis is text mining with R. 

After getting tweets from twitter, we use basic tools of data exploration to transform, visualize, and examine different features of the datasets, such as source, time, length, and content (e.g, link and picture) of the tweets. 

Next, we transform the datasets into tidy text format for sentiment analysis. The two main lexicons that we use are nrc and affin. 


```{r, warning = FALSE, message = FALSE}
#Loading packages.
library(rtweet)
library(tidyverse)
library(lubridate)
library(scales)
library(tidytext)
library(wordcloud)
library(textdata)

library(caret)       # for general model fitting
library(rpart)       # for fitting decision trees
library(rpart.plot)
library(ipred)       # for fitting bagged decision trees
library(ranger)
library(gbm)
library(vip)
```


```{r, include = FALSE, message = FALSE, warning = FALSE, echo = FALSE}
api_key <- "0000"
api_secret_key <- "0000"
access_token <- "0000"
access_token_secret <- "0000"

token <- create_token(
  app = "Hw9-alligators",
  consumer_key = api_key,
  consumer_secret = api_secret_key,
  access_token = access_token,
  access_secret = access_token_secret)
```



```{r, message = FALSE, warning = FALSE}

#Getting tweets

# Run these two lines to get the tweets 
# and then save them as a csv for future use
# tiktok <- get_timeline("tiktok_us", n=3200)
# tiktok %>% write_as_csv('tiktok.csv')
# 
# facebook <- get_timeline("Facebook", n=3200)
# facebook %>% write_as_csv("facebook.csv")

tiktok <-
  read_csv('tiktok.csv') %>% 
  select(status_id, source, text, created_at)

facebook <-
  read_csv('facebook.csv') %>% 
  select(status_id, source, text, created_at)

nrc <- read_rds("nrc.rds")

facebook %>% head()
```

```{r}
facebook %>%
  count(source, hour = hour(with_tz(created_at, "EST"))) %>%
  mutate(percent = n/sum(n)) %>%
  ggplot(aes(x = hour, y = percent, color = source)) +
  labs(x = "Hour of day (EST)", y = "% of tweets", color = "") + 
  scale_y_continuous(labels = percent_format()) +
  geom_line() +
  ggtitle('Facebook Source Breakdown by Hour')

tiktok %>%
  count(source, hour = hour(with_tz(created_at, "EST"))) %>%
  mutate(percent = n/sum(n)) %>%
  ggplot(aes(x = hour, y = percent, color = source)) +
  labs(x = "Hour of day (EST)", y = "% of tweets", color = "") + 
  scale_y_continuous(labels = percent_format()) +
  geom_line() +
  ggtitle('Tiktok Source Breakdown by Hour')


```
These above figures indicate Tiktok/Facebook breakdown by hour. 

```{r}
fb_wordcounts <- 
  facebook %>%
  mutate(tweetLength = str_length(text)) %>% 
  filter(tweetLength < 500)

tiktok_wordcounts <- 
  tiktok %>%
  mutate(tweetLength = str_length(text)) %>% 
  filter(tweetLength < 500)

writeLines(c(paste0("Facebook Mean Tweet Length: ", 
                  mean(fb_wordcounts$tweetLength)), 
           paste0("TikTok Mean Tweet Length: ", 
                  mean(tiktok_wordcounts$tweetLength))))

hist(tiktok_wordcounts$tweetLength)

hist(fb_wordcounts$tweetLength)

```

```{r}
fb_picture_counts <- 
  facebook %>%
  filter(!str_detect(text, '^"')) %>%
  count(picture = ifelse(str_detect(text, "t.co"),
                         "Picture/link", "No picture/link"))

tiktok_picture_counts <- 
  tiktok %>%
  filter(!str_detect(text, '^"')) %>%
  count(picture = ifelse(str_detect(text, "t.co"),
                         "Picture/link", "No picture/link"))

barplot(fb_picture_counts$n, 
        names.arg=c("No picture/link", "Picture/link"),
        main = "Facebook # of Tweets with and without pics/link")

barplot(tiktok_picture_counts$n, 
        names.arg=c("No picture/link", "Picture/link"),
        main = "Tiktok # of Tweets with and without pics/link")

```

```{r}
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"

# Unnest the text strings into a data frame of words
fb_words <- 
  facebook %>%
  filter(!str_detect(text, '^"')) %>%
  mutate(text = str_replace_all(text, 
                                "https://t.co/[A-Za-z\\d]+|&amp;", 
                                "")) %>%
  unnest_tokens(word, text, 
                token = "regex", 
                pattern = reg) %>%
  filter(!word %in% stop_words$word,
         str_detect(word, "[a-z]"))

tiktok_words <- 
  tiktok %>%
  filter(!str_detect(text, '^"')) %>%
  mutate(text = str_replace_all(text, 
                                "https://t.co/[A-Za-z\\d]+|&amp;", 
                                "")) %>%
  unnest_tokens(word, text, 
                token = "regex", 
                pattern = reg) %>%
  filter(!word %in% stop_words$word,
         str_detect(word, "[a-z]"))

# Inspect the first six rows of tweet_words
head(fb_words)
```

```{r}
fb_words %>%
  count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = "identity") +
  ylab("Occurrences") +
  coord_flip()

tiktok_words %>%
  count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = "identity") +
  ylab("Occurrences") +
  coord_flip()
```

```{r}
fb_sentiment <-    
 inner_join(fb_words, nrc, by = "word") %>% 
            group_by(sentiment)  

tiktok_sentiment <-    
 inner_join(tiktok_words, nrc, by = "word") %>% 
            group_by(sentiment) 

fb_words %>% head()
```

Here we compare the sentiment between Facebook and TikTok. It looks like discussions surrounding Facebook uses more trust words while topics about TikTok uses more words that reflect anticipation.

```{r}
fb_sentiment_analysis <- fb_sentiment %>% 
  count(word, sentiment) %>% 
  group_by(sentiment)

fb_sentiment_analysis %>%  
  top_n(15) %>% 
  ggplot(aes(x = sentiment, y = n )) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Frequency") +
  xlab("Sentiment") +
  labs(title="Facebook Sentiment")

tiktok_sentiment_analysis <- tiktok_sentiment %>% 
  count(word, sentiment) %>% 
  group_by(sentiment)

tiktok_sentiment_analysis %>%  
  top_n(15) %>% 
  ggplot(aes(x = sentiment, y = n )) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Frequency") +
  xlab("Sentiment") +
  labs(title="TikTok Sentiment")

```
```{r}
fb_sentiment_analysis %>% filter(!sentiment %in% c("positive", "negative")) %>% 
  mutate(sentiment = reorder(sentiment, -n),
         word = reorder(word, -n)) %>% top_n(10) -> fb_sentiment_analysis2

ggplot(fb_sentiment_analysis2, aes(x=word, y=n, fill = n)) +
  facet_wrap(~ sentiment, scales = "free")+ 
  geom_bar(stat ="identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(y="count", title="Facebook Sentiment")


tiktok_sentiment_analysis %>% filter(!sentiment %in% c("positive", "negative")) %>% 
  mutate(sentiment = reorder(sentiment, -n),
         word = reorder(word, -n)) %>% top_n(10) -> tiktok_sentiment_analysis2

ggplot(tiktok_sentiment_analysis2, aes(x=word, y=n, fill = n)) +
  facet_wrap(~ sentiment, scales = "free")+ 
  geom_bar(stat ="identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(y="count", title="Tik Tok Sentiment")


```
We also want to visualize common words on Facebook and Tiktok by wordccloud. The visual depiction indicates to us that "learn", "center" and "report" are common words, with more secondary common words such as "secure" page", and "visit" for Facebook account engagement. This could be that Facebook users tweet about account issues. Whereas, TikTok has "top", "tomorrow", and "prizes" as common words, and more secondary common words such as "winner, "nominating", and "grand", indicating that the social media platform likes to promote competitions or giveaways, which makes sense given their younger demographics might enjoy these types of rewards and games.


```{r, warning = FALSE, message = FALSE}
facebook_cloud <- fb_words  %>% count(word) %>% arrange(-n)
wordcloud(facebook_cloud$word, facebook_cloud$n, max.words = 200, colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"))

tiktok_cloud <- tiktok_words  %>% count(word) %>% arrange(-n)
wordcloud(tiktok_cloud$word, tiktok_cloud$n, max.words = 200, colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"))


```


Next, we examine texts on Facebook and Tiktok to see their positive-negative score by using afinn lexicon 

```{r, message = FALSE, warning = FALSE}
# run this to get afinn lexicon and save it as a csv
# get_sentiments ("afinn") -> afinn
#
#afinn %>% write_as_csv("afinn.csv")

afinn <- read_csv('afinn.csv')
```

```{r}
fb_afinn <-    
 inner_join(fb_words, afinn, by = "word") 

tiktok_afinn <-    
 inner_join(tiktok_words, afinn, by = "word")

fb_afinn %>% summarise(mean_fb_afinn = mean(value))
tiktok_afinn %>% summarise(mean_tt_afinn = mean(value))


```

Mean of Facebook's afinn value is 0.79 while mean of Tiktok's afinn value is 1.704293. In general, tweets from Tiktok are more positive than those on Facebook. 


Here, we predict the user based on the tweet length and number of words for each sentiment. TikTok is encoded as 1, and Facebook is encoded as 0.

```{r}
fb_sentiment_counts <- 
  fb_sentiment %>% 
  group_by(status_id) %>% 
  count(sentiment) %>% 
  pivot_wider(id_cols = status_id, 
              names_from = sentiment, 
              values_from = n,
              values_fill = 0)

tiktok_sentiment_counts <- 
  tiktok_sentiment %>% 
  group_by(status_id) %>% 
  count(sentiment) %>% 
  pivot_wider(id_cols = status_id, 
              names_from = sentiment, 
              values_from = n,
              values_fill = 0)

tiktok_feature_selection <- 
  tiktok_wordcounts %>% 
  mutate(user = 1) %>% 
  left_join(tiktok_sentiment_counts, 
            by="status_id")

facebook_feature_selection <-
  fb_wordcounts %>% 
  mutate(user = 0) %>% 
  left_join(fb_sentiment_counts, 
            by="status_id")

both_users <- 
  tiktok_feature_selection %>% 
  rbind(facebook_feature_selection) %>%
  mutate_if(is.numeric,coalesce,0)

set.seed(123)
index <- 
  createDataPartition(both_users$user,
                      p = 0.8, list = FALSE)

for_decisiontree <-
  both_users %>% select(-1,-2,-3,-4)

train <- for_decisiontree[index, ]
test  <- for_decisiontree[-index, ]

simple_model <- rpart(user ~ ., data = train, method = "class")
rpart.plot(simple_model, yesno = 2)
```

```{r, warning = FALSE}
set.seed(123)
bagging_model <- train(
  user ~ .,
  data = train,
  method = "treebag",
  trControl = trainControl(method = "oob"),
  keepX = T,
  nbagg = 100,
  importance = "impurity",
  control = rpart.control(minsplit = 2, cp = 0)
)

n_features <- length(setdiff(names(train), "user"))

rf_model <- ranger(
  user ~ .,
  data = train,
  mtry = floor(n_features * 0.5),
  respect.unordered.factors = "order",
  importance = "permutation",
  seed = 123
)


set.seed(123)  # for reproducibility
gbm_model <- gbm(
  formula = user ~ .,
  data = train,
  distribution = "gaussian",  # SSE loss function
  n.trees = 1000,
  shrinkage = 0.05,
  interaction.depth = 5,
  n.minobsinnode = 4,
  cv.folds = 10
)
```

```{r}
actual_train <- train$user

simple_pred_train <- 
  predict(simple_model, newdata = train) %>% 
  as_tibble() %>% 
  select(2) %>% 
  unlist() %>% 
  as.vector()
rss_simple_train <- sum((actual_train-simple_pred_train)^2)

bagging_pred_train <- 
  predict(bagging_model, newdata = train) %>% 
  as.vector()
rss_bagging_train <- sum((actual_train-bagging_pred_train)^2)

rf_pred_train <- predict(rf_model, data = train, seed = 123, verbose = T)[1] %>% unlist()
rss_rf_train <- sum((actual_train-rf_pred_train)^2)

gb_pred_train <- predict(gbm_model, newdata = train)
rss_gb_train <- sum((actual_train-gb_pred_train)^2)

cat(paste0("Residual Sum of Squares on Training Set\n",
           "\nSimple model: ", rss_simple_train, 
           "\nBagged model: ", rss_bagging_train, 
           "\nRandom forests model: ", rss_rf_train, 
           "\nGradient boost model: ", rss_gb_train))
```


```{r}
actual_test <- test$user

simple_pred_test <- 
  predict(simple_model, newdata = test) %>% 
  as_tibble() %>% 
  select(2) %>% 
  unlist() %>% 
  as.vector()
rss_simple_test <- sum((actual_test-simple_pred_test)^2)

bagging_pred_test <- 
  predict(bagging_model, newdata = test) %>% 
  as.vector()
rss_bagging_test <- sum((actual_test-bagging_pred_test)^2)

rf_pred_test <- predict(rf_model, data = test, seed = 123, verbose = T)[1] %>% unlist() %>% as.vector()
rss_rf_test <- sum((actual_test-rf_pred_test)^2)

gb_pred_test <- predict(gbm_model, newdata = test)
rss_gb_test <- sum((actual_test-gb_pred_test)^2)

cat(paste0("Residual Sum of Squares on Test Set\n",
           "\nSimple model: ", rss_simple_test, 
           "\nBagged model: ", rss_bagging_test, 
           "\nRandom forests model: ", rss_rf_test, 
           "\nGradient boost model: ", rss_gb_test))
```

The random forests model performed the best on the test set even though it was only second best for the training set. However, that may be an indication that the bagging model was overfit, which caused it to perform much worse on the test set than the random forests model.


## Evaluating Performance: Confusion Matrices

Now, I produce confusion matrices for all tree-based methods---first evaluating their performance on the test set. Note again that a Tiktok tweet is encoded as 1, and a Facebook tweet is encoded as 0. The code is shown for the first matrix but not for subsequent ones for the sake of elegance.

**Simple Model - Test Set:**

```{r}
simple_test_confusion <- 
  confusionMatrix(data = factor(round(simple_pred_test)),
                  reference = factor(actual_test), mode = "prec_recall")

simple_test_errors <- 
  simple_test_confusion$table[2] +
  simple_test_confusion$table[3]

simple_test_accuracy <-
  as.numeric(simple_test_confusion$overall[1])

simple_test_confusion
```
**Bagging Model - Test Set:**

```{r, echo = FALSE}
bagging_test_confusion <- 
  confusionMatrix(data = factor(round(bagging_pred_test)), 
                  reference = factor(actual_test), mode = "prec_recall")

bagging_test_errors <- 
  bagging_test_confusion$table[2] +
  bagging_test_confusion$table[3]

bagging_test_accuracy <-
  as.numeric(bagging_test_confusion$overall[1])

bagging_test_confusion
```
**Random Forests - Test Set:**

```{r, echo = FALSE}
rf_test_confusion <- 
  confusionMatrix(data = factor(round(rf_pred_test)), 
                  reference = factor(actual_test), mode = "prec_recall")

rf_test_errors <- 
  rf_test_confusion$table[2] +
  rf_test_confusion$table[3]

rf_test_accuracy <-
  as.numeric(rf_test_confusion$overall[1])

rf_test_confusion
```

**Gradient Boosting Model - Test Set:**

```{r, echo = FALSE}
gb_test_confusion <- 
  confusionMatrix(data = factor(round(gb_pred_test)), 
                  reference = factor(actual_test), mode = "prec_recall")

gb_test_errors <- 
  gb_test_confusion$table[2] +
  gb_test_confusion$table[3]

gb_test_accuracy <-
  as.numeric(gb_test_confusion$overall[1])

gb_test_confusion
```


## III. Results






## IV. Conclusion
Looking at the analyses, it seems that the Facebook and TikTok account and users tweet about these two social media platforms for different reasons. People tweeting about Facebook are likely to be reporting their account issues, which are associated with words such as "secure" and "trust." Whereas, people tweeting about TikTok seem to be participating in prize giveaways, which is associated with "anticipation" words such as "winning" and "tomorrow." Overall, these analyses make sense given the different demographics of the two social media platforms. 
